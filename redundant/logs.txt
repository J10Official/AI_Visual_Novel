Loading screenplay data from multiple files...
Found 27 screenplay files
Total scenes loaded: 5891
Converting to training format...
Map: 100%
 27089/27089 [00:01<00:00, 22687.82 examples/s]
Created dataset with 27089 examples
Clearing GPU memory...
The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Loading model with minimal memory footprint...
Loading checkpoint shards: 100%
 2/2 [00:06<00:00,  2.95s/it]
Trainable parameters: 3,194,880 / 2,617,536,768 (0.12%)
GPU Memory after model load: 6.41 GB
Tokenizing dataset...
Tokenizing dataset: 100%
 27089/27089 [00:03<00:00, 9233.63 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenized dataset: 27089 examples
Starting training with optimized memory settings...
GPU Memory before training: 6.41 GB
 [2231/2541 11:54:38 < 1:39:23, 0.05 it/s, Epoch 2.63/3]
Step	Training Loss
10	2.708600
20	2.966300
30	2.969500
40	2.612200
50	2.125100
60	1.855100
70	1.752200
80	1.612200
90	1.562600
100	1.386900
110	1.466300
120	1.319100
130	1.208600
140	1.308800
150	1.184000
160	1.214300
170	1.389200
180	1.201100
190	1.276500
200	1.247700
210	1.112700
220	1.286900
230	1.293100
240	1.188700
250	1.110500
260	1.159800
270	1.141600
280	1.168100
290	1.192900
300	1.234700
310	1.143800
320	1.212500
330	0.954600
340	1.069100
350	1.099300
360	1.165600
370	1.094600
380	1.059200
390	1.166500
400	1.168400
410	0.996800
420	1.013800
430	1.109300
440	1.088100
450	1.202600
460	1.020800
470	1.208600
480	1.185600
490	0.982400
500	1.118400
510	0.980300
520	0.945300
530	1.114200
540	1.061500
550	1.183200
560	0.957200
570	1.120100
580	1.185800
590	1.128000
600	1.098700
610	1.092700
620	1.196100
630	1.119200
640	1.094400
650	1.007900
660	1.109500
670	1.096600
680	1.054200
690	1.182800
700	0.963700
710	1.016700
720	0.980600
730	1.108100
740	1.018400
750	0.987600
760	1.084300
770	1.031500
780	1.043500
790	1.023800
800	1.082100
810	1.058500
820	1.093900
830	0.969700
840	1.077800
850	1.126300
860	1.054100
870	1.087000
880	1.190800
890	1.004600
900	0.908400
910	0.957100
920	1.017900
930	1.160700
940	1.049000
950	1.073700
960	0.926100
970	0.884900
980	1.108500
990	1.012000
1000	1.145500
1010	0.991100
1020	1.120400
1030	1.072300
1040	1.036200
1050	1.044000
1060	1.034700
1070	1.010300
1080	1.010100
1090	0.929700
1100	1.019400
1110	0.954700
1120	0.986300
1130	0.894500
1140	1.034300
1150	1.066100
1160	0.928900
1170	1.127800
1180	1.086400
1190	1.141500
1200	1.031700
1210	0.976200
1220	1.080900
1230	1.043300
1240	1.066500
1250	1.032300
1260	1.042200
1270	1.113700
1280	0.987500
1290	1.076000
1300	1.155700
1310	1.193400
1320	1.064000
1330	0.983700
1340	1.068800
1350	0.993000
1360	0.885200
1370	0.992000
1380	1.031600
1390	0.870200
1400	1.066400
1410	1.205000
1420	0.969900
1430	1.122700
1440	1.155700
1450	1.191200
1460	1.048500
1470	0.826000
1480	1.057200
1490	1.030700
1500	0.938700
1510	0.991800
1520	0.909000
1530	1.022800
1540	1.029900
1550	1.014100
1560	1.013400
1570	1.038900
1580	1.067100
1590	1.024500
1600	1.110000
1610	1.059400
1620	0.866200
1630	0.956700
1640	1.031500
1650	1.022100
1660	0.995300
1670	1.031700
1680	0.961000
1690	1.045400
1700	0.892400
1710	1.064200
1720	0.897300
1730	0.826700
1740	1.036200
1750	0.939200
1760	1.066900
1770	1.095200
1780	0.917000
1790	0.928800
1800	1.060400
1810	1.149500
1820	0.910000
1830	1.028200
1840	0.864500
1850	1.015500
1860	0.836100
1870	0.871300
1880	0.895400
1890	1.090500
1900	1.044800
1910	1.026800
1920	0.996800
1930	0.860700
1940	1.081100
1950	0.943400
1960	1.048600
1970	1.040100
1980	0.972200
1990	1.095400
2000	0.974000
2010	0.943400
2020	1.037800
2030	0.958900
2040	0.940600
2050	0.975700
2060	0.970400
2070	0.889900
2080	1.141600
2090	1.125100
2100	0.991400
2110	1.031500
2120	1.063300
2130	1.059400
2140	0.989800
2150	1.092600
2160	0.884300
2170	0.963900
2180	0.963300
2190	1.006600
2200	0.962700
2210	0.865900
2220	1.014100

==================================================
Saving fine-tuned model...
==================================================
✓ Model saved to: ./gemma2-screenplay-lora